\section{State of the Art}

\subsection{Heuristic Search Libraries}

Heuristic Search is a problem solving method that belongs to Artificial
Intelligence \cite{rusell-2003-aima} used in robotics, pathfinding, computer
gaming among other fields. Due to being more appropriate for the performance
that is in general desired, we can find that the most amount of work on
Heuristic Search is done in imperative, fast languages like C++ or Java.\\

In C++, we can find full search frameworks like \emph{HOG2} \cite{hog2},
\emph{Research code for heuristic search} \cite{cpp-search} or \emph{The
  Heuristic Search Research Framework} \cite{goldenberg-2017-framework}. All
these frameworks offer a full set of algorithms and procedures to override the
default implementations (such as cost, heuristic or expansion functions) in
order to adapt the library's behavior to the problem at hand. Also, these
frameworks offer visual representations options; a feature which is indeed the
main goal in the case of \emph{The Heuristic Search Research Framework}, that
offers a general visualization of algorithm behavior instead of domain specific
ones. On the other hand, in Java we can find similar projects like
\emph{Combinatorial Search for Java} \cite{cs4j} or \emph{AIMA}
\cite{java-aima}.\\

Trying to find similar projects in functional languages is more complicated
than that. However, one can find interesting projects like \emph{AIMA} written
in Common Lisp \cite{lisp-aima} or even a complete search framework written in
OCaml \cite{ocaml-search}. In Haskell, however, projects of this size are
nowhere to be found: All the algorithms are distributed in individual packages
with completely different implementations, as well as the data structures used
to perform the search.


\subsection{Haskell}

Haskell's first version was released in 1990 after the efforts of a committee
in FPCA '87 for creating an open standard for a ``non-strict, purely functional
language'' \cite{haskell-history}. Haskell's main features have remain patent
in the language, but constantly evolving: the language's main pillars are
\cite{haskell-98, haskell-2010}:

\begin{enumerate}
\item \textbf{Strong and statically typed}: the types are checked at compile
  time. That makes the run-time be sure that every function will get as
  parameter the expected object, making it more robust. However, no explicit
  type declaration is needed (although it is usually considered a good
  practice); types can be inferred most of the times by the compiler.
\item \textbf{Purely functional}: this type system is what allows Haskell to be
  purely functional. For Haskell, a string literal is of type \texttt{String},
  while an user's input on the prompt is a \texttt{IO String}. While at first
  shocking, this quality of Haskell maintains the referential transparency
  intact: the same function call with the same arguments is guaranteed to
  provide always the same output. All side effects are contained into monads
  (like the aforementioned \texttt{IO} monad) so they are contained and
  isolated.
\item \textbf{Lazy}: the fact that Haskell's evaluation is lazy (contrary to
  more common strict evaluation) means that a expression is only computed if
  its result is really necessary at a moment in time. This allows expressions
  to be defined in a much higher level: telling the computer what something is
  rather than how to compute it, and leaving the details of it to the compiler.
  Lazy evaluation provides for instance the use of infinite lists (since only
  the necessary part will be actually evaluated).
\item \textbf{Concurrent abstractions}: All the aforementioned characteristics
  also add up to the fact that the compiler is able to include concurrent
  optimizations into regular Haskell code thanks to its high-level definitions.
\end{enumerate}
  
\newpage